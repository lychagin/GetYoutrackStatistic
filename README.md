Данный скрипт предназначен для сбора проектных метрик из Youtrack, 
их аггрегации и сохранению в базе PostgreSQL для последующей удобной визуализации в open-source Datalens.
Метрики для отображения:
- Leadtime (предварительно расчитывается в Youtrack с помощью отдельного workflow правила).
- Спектральная диаграмма по Leadtime
- Перцентили (10%, 25%, 50%, 75%, 90%)
- Throughput (кол-во выполненных сторей за спринт и сравнение с запланированными)

На дашборде Datalens данные могут фильтроваться по командам, типам задач, спринтам, кварталам.
Дашборд содержит отдельный виджет показывающий последнее время запуска скрипта и его статус (OK, NOK).

Для удобства, база куда складыватся данные о виртуалках поднята вместе с DataLens.
Чтобы поднять ее, надо скачать DataLens: https://github.com/datalens-tech/datalens
Далее, в конец файла файла docker-compose.yaml нужно добавить несколько строчек:
  leadtime:
    image: postgres:latest
    container_name: pg_db
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: root
      POSTGRESS_DB: leadtime
    ports:
      - "5433:5432"
    volumes:
      - "./postgres_data:/var/lib/postgresql/data/"
      
Также, чтобы удаленно просматривать базу на хосте где развернут DataLens нужно пробросить порты:
ssh -l <login> -L 5455:localhost:5433 <ip of host with datalens>
После этого можно будет подсоединяться к базе скажем через DBeaver указывая адрес базы как localhost:5455 и имя базы: leadtime


Для поднятия проекта:
1. Устанавливаем виртуальное окружение: python -m venv .venv
2. Запускаем его: .venv\Scripts\Activate.bat
3. Устанавливаем необходимые проекты: pip install -r requirements.txt
4. Собираем образ докера из исходников: sudo docker build -t yt-metrics .

Дальше нужны подготовительные меры.

NOTE: В этой версии скрипта он использует внешнюю базу данных PostgreSql "pg_db".
      Она крутиться в отдельном конейнере и доступна из DataLens.
      В будущем будем использовать "коммунальную" базку.
      Локально у меня поднят конейнер с DataLens и постгрой.
      Чтобы дотянуться до базки pg_db из нашего приложения они должны быть в одной сети.
       
5. Создадим докерную сеть: sudo docker network create yt-net
6. Подключим к ней контейнер с базкой: sudo docker network connect yt-net pg_db
7. Создаем файл .env с токеном Youtrack. Формат строки в файле: YOUTRACK_TOKEN=<token>
   где <token> - токен со странички вашего профайла Youtrack
8. Стартанем наш контейнер в первый раз и подключим его к сети yt-net: sudo docker run --env-file ./.env --name yt-metr --network yt-net yt-metrics
9. Настраиваем в cron переодический запуск скрипта:
   запускаем настроку расписания: crontab -e
   Далее указываем:
   0 23 * * 1-5 /path-to-project/starter.sh
   По этой команде контейнер будет запускаться в 23:00 с понедельника по пятницу, а лог вывода будет созраняться в файл /home/<user>/cron.log
   Скрипт starter.sh запускает наш докер контейнер и проверяет его exit code.
   Скрипт также проверяет докерную сеть cost-net: подключен ли к ней контейнер pg_db (с базой данных).
   Если контейнер не подключен к сети, то подключает.
   Дальше он забрасывает дату запуска скрипта, логи и статус в базку.
   Оттуда данные выгребает дашборд. Таким образом мы на дашборде видем время обновления данных и статус запуска.
   
9. Для нормальной работы starter.sh установите на машины пакеты для работы с построй из консоли:
   sudo apt install postgresql-client-common
   sudo apt-get install postgresql-client

10. Обеспечьте возможность запуска psql без запроса пароля. Это нужно для работы скрипта.
    Для этого в домашней директории создайте файл .pgpass со следующей строчкой:
    localhost:5433:leadtime:<login>:<password>
    где <login> - логин для postgresql, а <password> - пароль для postgresql
    Ограничьте доступ к файлу: chmod 0600 .pgpass